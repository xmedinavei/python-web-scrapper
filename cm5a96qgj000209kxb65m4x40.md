---
title: "How to Create a Web Scraper Without Writing Code: Unlocking the Power of Prompt Engineering with ChatGPT"
seoTitle: "No-Code Web Scraping: Use ChatGPT Prompts"
seoDescription: "Learn to create a web scraper using ChatGPT without coding, harnessing the power of prompt engineering for AI-driven innovation"
datePublished: Sun Dec 29 2024 23:40:14 GMT+0000 (Coordinated Universal Time)
cuid: cm5a96qgj000209kxb65m4x40
slug: how-to-create-a-web-scraper-without-writing-code-unlocking-the-power-of-prompt-engineering-with-chatgpt
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1728351441365/cac13a53-cb41-42e8-aad7-f42c6047813e.png
tags: ai, programming, python, llm

---

In today's tech-savvy world, Artificial Intelligence (AI) is shaking things up in the best way possible. One of the shining stars in this arena is OpenAI's ChatGPT, which can understand and generate human-like text—even code! I recently embarked on a little adventure to build a web scraper for [BBC News](https://www.bbc.com/news) using ChatGPT, and guess what? I didn't write a single line of code. In this blog post, I'll share my journey and show you how **prompt engineering** played a pivotal role in making this happen.

But this isn't just about scraping news articles; it's about unlocking the potential of AI with prompt engineering to create a world of applications. So, buckle up and let's dive in!

## Introduction

Web scraping is a handy technique for pulling information from websites. Typically, it requires some coding chops—think Python, `requests`, and `BeautifulSoup`. But what if you could get the job done without any coding? Sounds like magic, right?

That's exactly what I set out to do. With ChatGPT as my coding companion, I aimed to create a fully functional web scraper through a series of well-crafted prompts and feedback. Along the way, I discovered just how crucial **prompt engineering** is in guiding AI to produce accurate and efficient code.

## The Initial Challenge

My mission was simple: build a Python web scraper that grabs news articles from the [BBC News website](https://www.bbc.com/news), capturing details like:

* Article URL
    
* Headline
    
* Description
    
* Image URL
    
* Image Description
    
* Tags
    
* Related URLs
    

To kick things off, I approached ChatGPT with a clear prompt and shared an HTML structure of the BBC News page, enriched with comments to guide the AI.

### Prompt to ChatGPT

*"I want to build a web scraper for BBC News in Python. The scraper should extract the article URL, headline, description, image URL, image description, tags, and related URLs. I'm sharing below the HTML structure with some comments that the AI should follow. These comments indicate where specific data points are located and highlight the conditions that may affect the scraping process. Please use these instructions to create a dynamic scraper capable of handling multiple articles, even if some articles lack images, descriptions, or other details."*

### Sample HTML Excerpt Provided

```xml
<!-- The 'data-testid' attribute is unique for each article, making it reliable for scraping. -->
<!-- XPath Example: //*[@id="main-content"]/article/section[1]/div/div[2]/div[1]/div/div/div[1]/a -->
<body>
  <div id="__next">
    <div class="app">
      <!-- Main content starts here -->
      <main id="main-content">
        <article>
          <!-- Sections containing articles; there may be multiple sections -->
          <section data-testid="virginia-section-outer-8">
            <div>
              <!-- Article cards start here; there may be zero, one, or multiple article cards -->
              <div data-testid="undefined-grid-8">
                <!-- Article card -->
                <div data-testid="london-card">
                  <!-- Anchor wrapper for the article -->
                  <div data-testid="anchor-inner-wrapper">
                    <!-- Here's the link to the article; extract 'href' as 'url' -->
                    <a href="/news/articles/c781vgy3918o" data-testid="internal-link">
                      <!-- Article content -->
                      <div data-testid="london-article">
                        <!-- Image section starts; some articles might not have images -->
                        <div data-testid="card-media-wrapper">
                          <div data-testid="card-media">
                            <div>
                              <!-- Extract 'src' as 'image_url' and 'alt' as 'image_description'; handle cases where these attributes are missing -->
                              <img
                                src="https://ichef.bbci.co.uk/news/480/cpsprodpb/1782/live/image.jpg.webp"
                                alt="Journalists take cover behind cars..."
                              />
                            </div>
                          </div>
                        </div>
                        <!-- Headline and description section -->
                        <div data-testid="card-text-wrapper">
                          <!-- Headline; not all articles will have this element -->
                          <h2 data-testid="card-headline">
                            Bowen: Year of killing and broken assumptions...
                          </h2>
                          <!-- Description; may or may not be present -->
                          <p data-testid="card-description">
                            Twelve months on from the 7 October attacks...
                          </p>
                          <!-- Tags and related URLs -->
                          <div>
                            <!-- Tags; an article could have zero, one, or multiple tags -->
                            <span data-testid="card-metadata-tag">Middle East</span>
                            <!-- Related URLs; extract links if available -->
                            <div data-testid="card-relatedUrls">
                              <a href="/news/related-article-1">Related Article 1</a>
                              <a href="/news/related-article-2">Related Article 2</a>
                            </div>
                          </div>
                        </div>
                      </div>
                    </a>
                  </div>
                </div>
                <!-- Additional article cards may follow... -->
              </div>
            </div>
          </section>
          <!-- More sections with articles might be present on the page -->
        </article>
      </main>
    </div>
  </div>
</body>
```

**Why This Matters:**

* **Detailed Comments:** By adding comments, I guided ChatGPT on where to look for each data point, pointing out elements like `'data-testid'` attributes and explaining that there could be zero, one, or multiple instances of each element.
    
* **XPath Examples:** Including XPath examples helped pinpoint the exact location of elements within the HTML structure, allowing the AI to handle different scenarios effectively.
    
* **Handling Variations:** I highlighted that some articles might not have images, descriptions, or tags, instructing the AI to handle such cases gracefully without throwing a fit.
    

This initial prompt and the detailed HTML sample, with comments, laid the groundwork for ChatGPT to understand the intricacies of the task. These comments not only served as a roadmap for finding the data but also provided context for the AI to create a dynamic web scraper capable of adapting to various scenarios.

## The Importance of Prompt Engineering

Prompt engineering is all about crafting inputs to AI models to get the best possible output. In this project, clear and detailed prompts were essential because:

1. **Setting Clear Objectives:** By specifying exactly what I wanted and providing annotated examples, I made sure ChatGPT knew the task and the nuances involved.
    
2. **Navigating Complexity:** Websites can have messy and nested HTML structures. Detailed prompts helped the AI navigate this complexity and account for variations.
    
3. **Iterative Refinement:** Each time the AI's output wasn't quite there, I gave specific feedback and updated prompts to fine-tune the results.
    
4. **Collaborative Problem-Solving:** Working with ChatGPT felt like having a coding buddy who could generate code based on my guidance.
    

## Overcoming Obstacles Through Iterative Feedback

### First Attempt: The Basic Scraper

ChatGPT initially whipped up a Python script using `requests` and `BeautifulSoup`. While it was a solid start, it only scraped a limited number of articles and missed several data points.

**Prompt to ChatGPT:**

*"The current scraper is not capturing all* `<section>` tags containing articles. Can you update the script to handle multiple sections and ensure that each section is fully scraped, even if some articles have missing fields like images or descriptions? Here's a reminder of the structure you should expect in the HTML."

#### Feedback and Prompt Refinement

* **Issue:** The scraper wasn't capturing all `<section>` tags containing articles.
    
* **Action:** I pointed out the additional `<section>` tags and emphasized the importance of handling multiple article cards within sections.
    
* **Result:** ChatGPT updated the script to loop through all `<section>` tags and handle multiple articles, boosting the article count.
    

### Handling Missing Data Fields

Despite the improvements, the scraper still missed some articles and didn't consistently extract `image_url` and `image_description`.

**Prompt to ChatGPT:**

*"I've noticed that the scraper is missing some image URLs and descriptions. In the HTML, the* `img` tag sometimes uses a `srcset` attribute for different image resolutions. Can you modify the code to extract the highest resolution image from the `srcset`, and handle cases where articles don't have images?"

#### Feedback and Prompt Refinement

* **Issue:** The `img` tags weren't always captured correctly, leading to missing images and descriptions.
    
* **Action:** I provided specific HTML snippets showing the problem and highlighted the need to parse the `srcset` attribute for high-resolution images. I also reminded the AI that some articles might not have images.
    
* **Result:** ChatGPT tweaked the code to extract the highest resolution image from the `srcset` attribute and included checks for missing images, enhancing data accuracy.
    

### Introducing Selenium for Dynamic Content

A significant hurdle popped up when the scraper couldn't retrieve images and articles loaded dynamically via JavaScript.

**Prompt to ChatGPT:**

*"The current scraper is still missing articles and images because some of the content on the BBC News website is rendered by JavaScript. Can you integrate Selenium into the script to handle dynamic content and ensure all elements are captured properly?"*

#### Feedback and Prompt Refinement

* **Issue:** The scraper was missing data because it couldn't handle JavaScript-rendered content.
    
* **Action:** I suggested using Selenium to render JavaScript content and provided examples where images and URLs were missing.
    
* **Result:** ChatGPT incorporated Selenium into the script, allowing it to interact with the webpage like a real browser, capturing all the dynamic content.
    

### Ensuring Complete Data Extraction with Scrolling

After adding Selenium, the scraper only grabbed 43 articles, whereas before, it had snagged over 110.

**Prompt to ChatGPT:**

*"It seems like we're still not getting all the articles after adding Selenium. The website likely uses lazy loading to display more content as you scroll. Can you update the Selenium script to simulate scrolling, so we can load and scrape all articles on the page?"*

#### Feedback and Prompt Refinement

* **Issue:** The reduced number of articles hinted that not all content was loading, possibly due to lazy loading as you scroll.
    
* **Action:** I observed this and suggested that the scraper might need to simulate scrolling to load all articles.
    
* **Result:** ChatGPT updated the script to include automatic scrolling, ensuring all articles were loaded and scraped. This brought the article count back over 110.
    

This approach of guiding ChatGPT with precise prompts at each step ensured that we could iteratively improve the web scraper, solving each problem systematically until we reached the final working product.

## The Final Product

Through this back-and-forth with ChatGPT, we ended up with a Python script that successfully scrapes the BBC News website, pulling all the desired data accurately.

### Key Features of the Final Scraper

* **Uses Selenium WebDriver:** Handles JavaScript-rendered content like a champ.
    
* **Implements Scrolling:** Simulates user scrolling to trigger lazy loading of content.
    
* **Extracts High-Resolution Images:** Parses the `srcset` attribute to get the best image quality.
    
* **Handles Variations in HTML Structure:** Adaptable to changes, including articles without images or descriptions.
    
* **Cleans and Organizes Data:** Removes duplicates and keeps the output consistent.
    

### Sample Output in JSON

```json
[
  {
    "url": "https://www.bbc.com/news/articles/c781vgy3918o",
    "image_url": "https://ichef.bbci.co.uk/news/1536/cpsprodpb/1782/live/image.jpg.webp",
    "image_description": "Journalists take cover behind cars as Israeli soldiers take position...",
    "headline": "Bowen: Year of killing and broken assumptions has taken Middle East to edge of deeper, wider war",
    "description": "Twelve months on from the 7 October attacks which led to Israel's war in Gaza...",
    "tags": ["Middle East"],
    "related_urls": [
      "https://www.bbc.com/news/related-article-1",
      "https://www.bbc.com/news/related-article-2"
    ]
  },
  {
    "url": "https://www.bbc.com/news/articles/cr54z4q11qvo",
    "image_url": "",
    "image_description": "",
    "headline": "Girl who lost eye in Israeli raid that killed father carries ‘pain mountains can't bear’",
    "description": "As the war in Gaza enters its second year, the BBC revisits three families whose lives have been fragmented by the conflict.",
    "tags": ["Middle East"],
    "related_urls": []
  }
  // ... more articles
]
```

## The Power of Prompt Engineering

This project really highlighted how crucial prompt engineering is when working with AI models like ChatGPT:

* **Precision Matters:** Specific and detailed prompts lead to more accurate and relevant AI outputs.
    
* **Providing Context:** Sharing annotated HTML and explaining potential variations helped the AI handle complex tasks.
    
* **Iterative Approach:** Continual feedback and refining prompts can overcome challenges and improve results.
    
* **Collaboration is Key:** Treating the AI as a partner, sharing insights and observations, can lead to powerful solutions.
    

## Real-World Applications of AI in Problem-Solving

This experience showed me how AI can be a game-changer in tackling practical challenges:

* **Automating Tasks:** AI can generate scripts to automate tasks like web scraping and data extraction.
    
* **Quick Prototyping:** You can use AI to rapidly create prototypes, saving time and effort.
    
* **Learning Tool:** AI can help you understand coding concepts and troubleshoot issues.
    
* **Data Analysis:** AI models can assist in analyzing large datasets, spotting patterns, and generating insights.
    
* **Content Creation:** Beyond code, AI can generate articles, summaries, and other text, aiding in content creation.
    
* **Personalized Solutions:** AI can provide tailored solutions based on your specific needs, boosting efficiency.
    

## Conclusion

Building a web scraper for [BBC News](https://www.bbc.com/news) using ChatGPT was not just about getting the job done without code; it was about exploring the synergy between human guidance and AI capabilities. By steering the AI with precise and iterative instructions, I created a fully functional scraper—no coding required!

But more than that, this journey showed me how AI and prompt engineering can open doors to creating all sorts of applications. The possibilities are endless, and that's pretty exciting!

---

If you're curious to see the full code or want to contribute, check out my [GitHub repository.](https://github.com/xmedinavei/python-web-scrapper.git)

Let's keep the conversation going! **What applications can you imagine building using AI and prompt engineering?** Share your thoughts in the comments below. Let's connect and explore how AI is revolutionizing software engineering together.